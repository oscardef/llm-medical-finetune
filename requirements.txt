# -------------------------------------------
# requirements.txt for TinyMistral-LoRA on RCP
#
#   - Works with CUDA 12.6 / PyTorch 2.7.0 (nvcr.io/nvidia/pytorch:23.11-py3)
#   - pins accelerate >=0.23.0 so that `clear_device_cache` exists
#   - pins transformers==4.52.4 so that TrainingArguments(evaluation_strategy=â€¦) is supported
# -------------------------------------------

transformers==4.52.4
datasets==3.6.0
sentencepiece==0.2.0

peft==0.15.2
bitsandbytes==0.46.0

# Bump accelerate to 0.32.x so that clear_device_cache actually exists
accelerate==1.7.0

torchvision==0.22.0            # matches torch 2.2.0a0 (CUDA 12.6)
